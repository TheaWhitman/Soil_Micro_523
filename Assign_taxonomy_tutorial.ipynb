{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning taxonomy, based on QIIME2's \"Atacama soil microbiome\",  \"Moving pictures\", and \"Training feature classifiers\" tutorials.\n",
    "\n",
    "https://docs.qiime2.org/2017.12/tutorials/atacama-soils/\n",
    "https://docs.qiime2.org/2017.12/tutorials/moving-pictures/\n",
    "https://docs.qiime2.org/2017.12/tutorials/feature-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will be taking the representative sequences from our OTU table and assigning taxonomy to them - i.e., we will look at a database of known organisms and their sequences, and will compare our own sequences to them.\n",
    "\n",
    "To do this effectively, we will need to trim / \"train\" the database, based on the specific portion of the 16S gene that we sequenced, using our specific primers. We will then use this \"trained\" classifier to classify our own sequences. \n",
    "\n",
    "The database we will be using is the \"Greengenes\" database (http://greengenes.secondgenome.com/downloads), but many others exist out there - for example, the Silva database is another commonly used reference (https://www.arb-silva.de/). For fungi, the UNITE database is popular (https://unite.ut.ee/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to train our classifier to be relevant for the reads that we actually sequenced. The Greengenes database contains full-length 16S sequences, but we only sequenced a short portion of this gene (150 bp). We will want to pull out the parts of the database that are relevant for our own amplicons.\n",
    "\n",
    "To do this, we need to provide reference sequences as input, what primers we used, how long our expected amplicon is, and what we want to call the output.\n",
    "\n",
    "However, actually training the dataset takes more memory than the virtual machine has, and takes a long time. Thus, for this tutorial, we're going to download the trained classifier from QIIME: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O \"classifier.qza\" \"https://data.qiime2.org/2017.12/common/gg-13-8-99-515-806-nb-classifier.qza\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the classify command need in order to run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime feature-classifier classify-sklearn --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the classifier to assign taxonomy to our own sequences. Use the help file above and the names of you input sequences and classifier to specify them in the command below. (Hint: look for which Options are [required], and remember you want .qza objects, not .qzv objects.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime feature-classifier classify-sklearn --XXX XXX --XXX XXX --o-classification taxonomy.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we've got our sample metadata from the first week, our OTU table from last week, and taxonomy data from this week. Let's put it all together and take a look at these samples.\n",
    "\n",
    "Explore the command qiime taxa barplot --help to figure out how to create a .qzv object summarizing these data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you remember how we view .qzv objects? What did you call your output object from the barplot command?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime tools view XXX.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next week we will look at how many of each OTU are in each sample, combined with the taxonomy, and begin considering distance matrices. We'll be doing those analyses in R, but using the R notebooks in Jupyter, so it will look similar. To prepare for that, we will save our sequences in a format that works outside of QIIME."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tutorial so far, we have the following files:\n",
    "\n",
    "- An OTU table with our samples and the abundance of each OTU in each sample (table.qza)\n",
    "- A file with the DNA sequence associated with each OTU (rep-seqs.qza)\n",
    "- A file with the predicted taxonomic identity of each OTU (taxonomy.qza)\n",
    "\n",
    "We will save them in a new directory we call OTU_table, and copy (\"cp\") our sample metadata there too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir OTU_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime tools export table.qza --output-dir OTU_table\n",
    "!qiime tools export rep-seqs.qza --output-dir OTU_table\n",
    "!qiime tools export taxonomy.qza --output-dir OTU_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp sample_metadata.tsv OTU_table/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls OTU_table/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above command shows two .tsv files, one .fasta file, and one .biom file, we should be ready to go for next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!biom add-metadata -i OTU_table/feature-table.biom -o OTU_table/feature-table-metaD.biom --sample-metadata-fp OTU_table/sample_metadata.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!biom add-metadata -i OTU_table/feature-table-metaD.biom -o OTU_table/feature-table-metaD-tax.biom --observation-metadata-fp OTU_table/taxonomy.tsv --sc-separated taxonomy --observation-header OTUID,taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!biom summarize-table -i OTU_table/feature-table-metaD-tax.biom -o OTU_table/feature-table-metaD-tax-summary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -20 OTU_table/feature-table-metaD-tax-summary.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
